{"meta":{"title":"Limbo's Wiki","subtitle":"","description":"","author":"Limbo","url":"http://yoursite.com","root":"/"},"pages":[{"title":"About","date":"2020-01-15T12:06:59.176Z","updated":"2020-01-15T12:06:59.176Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2020-01-15T12:06:59.177Z","updated":"2020-01-15T12:06:59.177Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2020-01-15T12:06:59.176Z","updated":"2020-01-15T12:06:59.176Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Class 文件结构","slug":"class_bytes","date":"2020-01-20T17:36:05.000Z","updated":"2020-01-20T17:36:05.000Z","comments":true,"path":"wiki/class_bytes/","link":"","permalink":"http://yoursite.com/wiki/class_bytes/","excerpt":"","text":"参考: https://coolshell.cn/articles/9229.html http://luckylau.tech/2017/05/26/%E4%BD%A0%E6%87%82java%E5%90%97-11/ 魔数0XCAFEBABE 版本号 常量池","categories":[],"tags":[]},{"title":"JVM Memory","slug":"Language/Java/jvm/jvm_mem","date":"2020-01-20T16:00:12.000Z","updated":"2020-01-20T16:00:12.000Z","comments":true,"path":"wiki/Language/Java/jvm/jvm_mem/","link":"","permalink":"http://yoursite.com/wiki/Language/Java/jvm/jvm_mem/","excerpt":"","text":"JVM 主要三个组成: Heap: 所有实例对象, 堆内空间无法扩展出现 OOM 异常 Young Generation(默认比例 8:1:1) Eden From Survivor To Survivor Old Generation Method Area(Non-Heap, PermGen, 永久代): 方法区存储类信息, 常量, 静态变量等数据, 线程共享区域, 方法区也会抛出 OOM Stack Java Stack: 每个方法执行的时候都会创建一个 stack frame, 保存局部变量, 操作栈,动态链接, 方法出口等, 如果线程请求栈的深度大于虚拟机允许深度, 抛出 stackoverflow 异常, 如果虚拟机栈可以动态扩展, 当无法申请内存是会抛出 OOM 异常 Native Method Stack: 存一些原生方法, C 库 参数配置 其他内存占用NIONIO使用java.nio.ByteBuffer.allocateDirect()方法分配内存，每次分配内存都会调用操作系统函数os::malloc()，所以，分配的内存是本机的内存而不是Java堆上的内存； 另外利用该方法产生的数据和网络、磁盘发生交互的时候都是在内核空间发生的，不需要复制到用户空间Java内存中，这种技术避免了Java堆和本机堆之间的数据复制；但是利用该方法生成的数据会作为Java堆GC的一部分来自动清理本机缓冲区。 异常","categories":[{"name":"Language","slug":"Language","permalink":"http://yoursite.com/categories/Language/"},{"name":"Java","slug":"Language/Java","permalink":"http://yoursite.com/categories/Language/Java/"},{"name":"jvm","slug":"Language/Java/jvm","permalink":"http://yoursite.com/categories/Language/Java/jvm/"}],"tags":[]},{"title":"欢迎来到我的 Wiki","slug":"index","date":"2020-01-20T15:45:04.000Z","updated":"2020-01-20T15:45:04.000Z","comments":true,"path":"wiki/index/","link":"","permalink":"http://yoursite.com/wiki/index/","excerpt":"","text":"一直在找代替 Blog 的工具, 发现 Wiki 更适合知识体系的构建, 经常性的总结比记流水帐更有效果","categories":[],"tags":[]},{"title":"","slug":"BigData/Kafka/cheat_sheet","date":"2020-01-15T12:06:59.175Z","updated":"2020-01-15T12:06:59.175Z","comments":true,"path":"wiki/BigData/Kafka/cheat_sheet/","link":"","permalink":"http://yoursite.com/wiki/BigData/Kafka/cheat_sheet/","excerpt":"","text":"","categories":[{"name":"BigData","slug":"BigData","permalink":"http://yoursite.com/categories/BigData/"},{"name":"Kafka","slug":"BigData/Kafka","permalink":"http://yoursite.com/categories/BigData/Kafka/"}],"tags":[]},{"title":"crontab","slug":"Linux/crontab","date":"2020-01-15T12:06:59.174Z","updated":"2020-01-15T12:12:26.138Z","comments":true,"path":"wiki/Linux/crontab/","link":"","permalink":"http://yoursite.com/wiki/Linux/crontab/","excerpt":"","text":"123456789101112131415[xuxiao.xu@l-rtools1.ops.cna ~]$ cat /etc/crontabSHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed https://crontab.guru/","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[]},{"title":"包管理系统","slug":"Linux/package","date":"2020-01-15T12:06:59.173Z","updated":"2020-01-21T08:38:45.551Z","comments":true,"path":"wiki/Linux/package/","link":"","permalink":"http://yoursite.com/wiki/Linux/package/","excerpt":"","text":"","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[]},{"title":"Maven 汇总","slug":"Language/Java/maven","date":"2020-01-15T12:06:59.168Z","updated":"2020-01-15T12:06:59.169Z","comments":true,"path":"wiki/Language/Java/maven/","link":"","permalink":"http://yoursite.com/wiki/Language/Java/maven/","excerpt":"","text":"Maven 是常用的 Java 构建工具, 以 POM 文件为中心, Maven 工作时的几个主要步骤 读取 pom.xml 下载依赖到本地 执行构建过程 执行插件 POMPOM - Project Object Model 具体可参见 官网 POM 介绍 依赖包管理 Maven 会递归下载 POM 文件中的依赖, 可以用 &lt;exclusions&gt; 进行排除 Maven 下载的依赖来自 3 个地方: 本地 %USER_HOME%/.m2 目录 中央仓库 远程库 理解 Lifecycle, Phase, Goal Lifecycle上面图里可以看到 Maven 自带 3 个 Lifecycle: default: 主要生命周期, 编译代码并处理打包项目 clean: 清理构建输出, 包括中间文件 site: 文档生成 Phasedefault 的 Lifecycle 包含了许多 phase, 常见如下, 完整可以查看 Lifecycle Referrence validate: 验证项目 compile: 编译代码 test: 测试 package: 将编译后代码打包 install: 安装到本地存储 deploy: 发布到远程仓库 当我们执行 mvn install 时, 实际会按照顺序执行前置的各个 phase, 例如 validate -&gt; compile -&gt; test -&gt; package -&gt; install 最终执行到 install GoalMaven 为插件提供了 Goal 来注册到各个 phase 进行执行 Maven 是如何组合这些过程的在 POM 中有一个 &lt;packaging&gt; 选项, 默认会是 jar, 这个 packaging 会绑定一些 goal 到各个 phase, 默认可查看 Plugin Bindings, 举个例子 jar 的默认绑定: Phase plugin:goal process-resources resources:resources compile compiler:compile process-test-resources resources:testResources test-compile compiler:testCompile test surefire:test package jar:jar install install:install deploy deploy:deploy Maven 在按照 lifecycle 进行运行的时候会执行各个 phase 中的 goal Scope如果我们想要在不同阶段对打包进行控制, 可以设置 scope 参数, 官网 对应不通的编译阶段我们可以参考下图 compile: 默认设置, 参与整个打包的周期 provided: 比如说我们提交 Flink 任务到集群里, 很多包集群是已经附带的, 我们就可以把该包设置成 provided, 减少打包体积 runtime: 这个一般用 jdbc 可以选填, 只有在运行时才需要 test: 测试阶段用到的包 system: 从本地引用包, 不会去仓库下载, 配合 systemPath 使用 对于依赖的传递, 可以举例: A - comiple -&gt; B - provided -&gt; C 或者A - comiple -&gt; B - test -&gt; C 时 A 将丢弃 C, 不会引用 下面是具体的引用传递: 资料 Maven 官网 Maven 教程","categories":[{"name":"Language","slug":"Language","permalink":"http://yoursite.com/categories/Language/"},{"name":"Java","slug":"Language/Java","permalink":"http://yoursite.com/categories/Language/Java/"}],"tags":[]},{"title":"JVM 简介 (翻译)","slug":"Language/Java/jvm/jvm","date":"2020-01-15T12:06:59.168Z","updated":"2020-01-15T12:06:59.168Z","comments":true,"path":"wiki/Language/Java/jvm/jvm/","link":"","permalink":"http://yoursite.com/wiki/Language/Java/jvm/jvm/","excerpt":"","text":"https://www.guru99.com/java-virtual-machine-jvm.html 什么是 JVM ?Java Virtual Machine (JVM) 是提供 Java 代码和应用运行环境的引擎. 它可以将 Java 字节码转换成机器码. JVM 是 Java Run Environment (JRE) 的一部分. 在其他语言里, 编译器为特定的系统产生机器码, 然而, Java 编译器产生的代码直接提供给虚拟机, 就是我们熟知的 JVM JVM 如何工作首先, Java 代码编译成字节码. 这个字节码可以在不同的机器上解析. 字节码是介于主机系统和 Java 源码之间的中间语言. JVM 负责分配内存空间 JVM 架构让我们来了解下 JVM 的架构. 它包含了 classloader, memory area, execution egine 等. ClassLoader: 类加载器是一个加载类文件的子系统, 包括 3 个主要功能, Loading, Linking 和 Initialization Method Area: JVM 方法区保存像 metadata, 持久的运行池和代码方法 Heap: 所有的 Object, 他们相关的 instance 变量, 数组都存在 heap 里, 这些内存可以在不同线程间分享 JVM Language Stacks: 存储 local 变量, 和一部分结果. 每个线程都有自己的 JVM stack, 创建线程的同时它们也会被创建. 当一个方法被 invoke 时, 新的 frame 就会被创建, 当方法 invocation process 完成时也就会被删除. PC Registers: 保存正在执行的代码地址. 在 Java 中, 每个线程有自己的 PC register. Native Method Stacks: 保存原生库的地方. 通常都是其他语言的代码. Execution Engine: It is a type of software used to test hardware, software, or complete systems. The test execution engine never carries any information about the tested product. Native Method interface: 编程框架. 允许 Java 代码在 JVM 里调用库和原生应用. Native Method Libraries: Execution Engine 需要的一些原生库(C, C++) 代码编译和执行过程为了书写和执行一个软件, 你需要: Editor: 输入你的代码 Compile: 讲你的高级语言转换成机器语言 Linker: 将不同的程序文件合并在你的 main 程序里. Loader: 讲文件从硬盘里加载到 RAM 里. Loading 的过程是在执行代码的时候自动执行的 Execution: 通过操作系统和进程来执行你的代码 C 代码编译和执行过程为了理解 Java 编译过程, 先让我们简单看一下 C 语言是如何编译和链接的 假设你的 main 函数里调用了 f1 和 f2 两个函数. main 函数保存在 a1.c 文件里 f1 函数保存在 a2.c 文件里 f2 函数保存在 a3.c 文件里 所有文件, a1.c, a2.c 和 a3.c 通过 compiler 输出为机器码 下一步就是通过 linker 将所有这些 object 文件打包成一个 exe 文件 在程序运行期间, 一个 loader 程序将会把 a.exe load 进 Ram 里来执行 Java 代码在 JVM 里编译和执行让我们看看 Java 程序. 在你的 main 函数里有 f1 , f2 两个函数 main 方法存在 a1.java 文件 f1 存在 a2.java 文件 f2 存在 a3.java 文件 compiller 将会产出 3 个以 .class 命名的字节码文件. 不像 C, 没有 linking 的过程. JVM 存在于 RAM 中. 在执行期间, 使用 class loader 把 class 文件装载进 RAM, 下一步, execution engine 将会把字节码转换为机器码,这是在 compile 时候进行的. 这就是为什么相对来说 Java 运行的比较慢. NOTE: JIT 或者说 Just-in-time compiler 是 JVM 的一部分. It interprets part of the Byte Code that has similar functionality at the same time. 为什么 Java 既是解析又是编译语言?程序语言分类 高级语言: C++, Java 中等语言: C 低级语言: Assembly 最低级语言: 机器语言 compiler 可以将一个程序从一级语言转化为另一级语言, 例如将 C++ 转为机器语言 java compiler 将高级的 java 代码转换为字节码(也是一种机器码) interpreter 可以将同一级别的语言转化为相同级别的语言.例如 Java 程序转换为 C++ 在 Java 中 JIT 将字节码转换为机器码是相同语言级别的转换 所以, Java 既是解析又是编译语言 为什么 Java 慢?主要两个原因: 动态链接: 不像 C, Java 在运行时链接 运行时解析: 字节码是在运行时转换为机器码. 所以速度有所减慢","categories":[{"name":"Language","slug":"Language","permalink":"http://yoursite.com/categories/Language/"},{"name":"Java","slug":"Language/Java","permalink":"http://yoursite.com/categories/Language/Java/"},{"name":"jvm","slug":"Language/Java/jvm","permalink":"http://yoursite.com/categories/Language/Java/jvm/"}],"tags":[]},{"title":"RAID","slug":"Hardware/Disk/raid","date":"2020-01-15T12:06:59.165Z","updated":"2020-01-15T12:06:59.165Z","comments":true,"path":"wiki/Hardware/Disk/raid/","link":"","permalink":"http://yoursite.com/wiki/Hardware/Disk/raid/","excerpt":"","text":"RAID是英文Redundant Array of Independent Disks的缩写, 即磁盘冗余阵列. RAID 0分散打在不同磁盘上, 写入速度 * n RAID 1镜像对考， 双写 RAID 5校验块分布在不同磁盘上, 易于扩展 Raid 6采用两种独立的校验算法 RAID 组合组合方式, 速度既快, 又有备份","categories":[{"name":"Hardware","slug":"Hardware","permalink":"http://yoursite.com/categories/Hardware/"},{"name":"Disk","slug":"Hardware/Disk","permalink":"http://yoursite.com/categories/Hardware/Disk/"}],"tags":[]},{"title":"硬盘接口","slug":"Hardware/Disk/interface","date":"2020-01-15T12:06:59.165Z","updated":"2020-01-15T12:06:59.165Z","comments":true,"path":"wiki/Hardware/Disk/interface/","link":"","permalink":"http://yoursite.com/wiki/Hardware/Disk/interface/","excerpt":"","text":"名称 总线 物理接口 协议 年份 带宽 理论速度 编码 SATA 1.0 SATA SATA AHCI 2003 1.5 Gb/s 150 MB/s 8 b / 10 b SATA 2.0 SATA SATA AHCI 2004 3 Gb/s 300 MB/s 8 b / 10 b SATA 3.0 SATA SATA AHCI 2009 6 Gb/s 600 MB/s 8 b / 10 b SATA Express(SATA 3.2) SATA SATA 2014 16 Gb/s 1969 MB/s 128 b / 130 b M.2 SATA SATA M.2 AHCI 2013 6 Gb/s 600 MB/s M.2 NVMe NVMe M.2 PCIe 2013 32 Gb/s 3200 MB/s 上面这个图有点问题, Technology 那一行的 SATA 都改为 AHCI","categories":[{"name":"Hardware","slug":"Hardware","permalink":"http://yoursite.com/categories/Hardware/"},{"name":"Disk","slug":"Hardware/Disk","permalink":"http://yoursite.com/categories/Hardware/Disk/"}],"tags":[]},{"title":"Wi-Fi 协议","slug":"Hardware/wifi","date":"2020-01-15T12:06:59.164Z","updated":"2020-01-15T12:06:59.164Z","comments":true,"path":"wiki/Hardware/wifi/","link":"","permalink":"http://yoursite.com/wiki/Hardware/wifi/","excerpt":"","text":"名称 代号 年代 频段 带宽 802.11b Wi-Fi 1 1999 2.4 GHz 11 Mbps 802.11a Wi-Fi 2 1999 5 GHz 54 Mbps 802.11g Wi-Fi 3 2003 2.4 GHz 54 Mbps 802.11n Wi-Fi 4 2009 2.4 GHz / 5 GHz 450 Mbps 802.11ac Wi-Fi 5 2014 2.4 GHz / 5 GHz 866.7 Mbps 802.11ax Wi-Fi 6 2019 2.4 GHz / 5 GHz 1201 Mbps","categories":[{"name":"Hardware","slug":"Hardware","permalink":"http://yoursite.com/categories/Hardware/"}],"tags":[]},{"title":"Hello World","slug":"Blog/hello-world","date":"2020-01-15T12:06:59.162Z","updated":"2020-01-20T16:16:20.000Z","comments":true,"path":"wiki/Blog/hello-world/","link":"","permalink":"http://yoursite.com/wiki/Blog/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Blog","slug":"Blog","permalink":"http://yoursite.com/categories/Blog/"}],"tags":[]},{"title":"Flink 如何工作的?","slug":"BigData/flink","date":"2019-12-17T12:19:05.000Z","updated":"2020-01-15T12:06:59.175Z","comments":true,"path":"wiki/BigData/flink/","link":"","permalink":"http://yoursite.com/wiki/BigData/flink/","excerpt":"","text":"Flink 是如何工作的? 本文主要分为两个部分, 分别介绍 Flink 集群的启动和 Flink 任务如何运行在集群中(Stream 方式), 由于篇幅有限, 本文尽量不探讨具体的实现细节,但是比较重要的部分给予一定的说明, 更多的是让读者了解 Flink 内部的工作原理. Flink 在部署上主要分为两部分 JobManager 和 TaskManager, JobManager 主要负责任务的分发, slot 资源管理等, TaskManager 则主要负责任务的运行. 下面这张官网的架构图虽然年代有点久远, 但至今大部分功能还是如图所述. 从上面图中需要了解的信息: Flink 代码在客户端里进行了”编译”, 然后提交给 JobManager, 这里比较重要, 因为很多 Optimizer 的东西都可以在这里做 JobManager 拿到”编译”后的 job 再分发到各个 TaskManager 的 Slot 里 Flink 有两种通信方式, 远程调用使用的是 Actor, TaskManager 数据传输使用的是 Netty JobManager 集成了 Scheduler 和 Checkpoint Coordinator 等主要功能 1 Flink 集群的启动Flink 集群的启动方式主要分为以下 3 种: Standalone 方式: 最基础的方式, 具有完整的功能, 可在实体机上进行部署 Cluster session 方式: 部署在像 Yarn , K8s 等资源调度框架内, 直接建立起集群, 然后通过与 JobManager 交互来提交作业, 但是在实际生产过程中发现有严重的 Bug 还没有解决, 可参看 FLINK-11205 , 主要是 Metaspace 空间无法释放导致 TaskManager 被 kill, 而一个集群里存在多个 TaskManager 问题更加严重, 会导致整个集群 Taskmanager 不断重启. Per Job 方式: 在 Yarn 中已经很好的集成了这种方式, 就是整个集群的生命周期和任务进行绑定, 任务结束, 集群资源也随着撤销, 唯一的缺点就是部署时间上不如 Cluster session 的方式, 这点其实在实际生产中可以忽略. 1.1 JobManager 的启动因为版本变动的关系 Jobmanager 在 1.5 版本的时候进行了一次大改, 和上面的图可能略有不通, 具体可以参见 FLIP-6, 下面聊一聊一般生产中 JobManager 如何启动的. 上图可以看出在 1.5 以后的新版本中 JobManager 多出了两个组件, 一个是 ResourceManager, 主要负责管理 Flink 自己的 TaskManager 资源, 注意这个 ResourceManager 和 Yarn 上的不是同一个, 两者管理的资源不是同一级别, 第二个是 Dispatcher 主要是提供 client 的 RPC 接口, 提供发布任务的一系列功能. 而 JobMaster 主要负责一个任务的生命周期, 每个 Flink Job 都有一个 JobMaster 与之对应. 1.2 TaskManager 的启动TaskManager 其实功能比较简单, 提供一些基本的 RPC 服务, 供 JobManager 进行调度, 稍后会讲到 TaskManager 如何运行 JobManager 提供的 subTask. 2 Flink Job 的启动我们先来看看一个 Flink job 的构成 Flink job 最核心的构成其实就是这个 ENV, 用户需要通过调用 ENV 来注册用户的代码逻辑, 而这个 ENV 定义了一系列 DAG 生成的规则, 比如 env.addSource 我们必须指定 Source 的类型, 是 DataStream 还是 DataSet, 又比如 keyBy 之后返回的是 KeyedStream, 这些规则都是在 ENV 里进行了定义, 用户只要根据规则来使用即可, 而且根据 ENV 的定义我们可以在不同的环境中运行 Flink Job, 如下图所示: 我们可以以 Flink 开发者的角度思考如何从用户代码到底层实现, 这一过程必然使用分层结构, 下面来看一下各个层级的工作: 2.1 Client 端首先在 Client 端生成的第一层是 User Rule, 这个算是用户代码到 DAG 的第一层抽象, 这里面制定了很多规则, 来约束用户的行为, 引导用户更好的使用 Flink 程序. 第二层是 Transformation 层, 这里的 Transformation 主要是完成了对用户的各个算子的定义, 比如说 addSource 的操作即为 SourceTransformation, filter 操作即为 OneInputTransformation, 这里面与用户的算子一一对应, 但是这里面区分定义了 PhysicalTransformation, PhysicalTransformastion 可以理解为物理算子, 需要计算资源进行计算, 而 union, select 这些并非物理算子, 可以在后面的结构中通过网络 shuffle 进行合并, 在这一步我们得到的还是一个 Transformation 的列表, 完整的描述了用户定义的各个算子, 如下图所示: 第三层就是我们的 StreamGraph 了, 从 Transformation 转化而来, 构成了图的结构, 其中 StreamNode 为点, StreamEdge 为边, 在程序里存入的部分是一张链表结构, 如下图所示: 这里面加入了一些信息, 比如说 slotSharingGroup, 从而定义这些算子如何在 slot 里分配 在 Client 里生成的最后一层即为 JobGraph, 这也是 Flink JobManager 接收的任务对象, 其实上一层的 StreamGraph 已经完成了任务 DAG , 为什么还需要 JobGraph 呢, 其实是为了兼容 Batch 模式, JobGraph 作为统一层进行封装, 同时提供了计算优化即 setChain 功能, 可以减小序列化和网络开销, 可能有的同学会对 chain 的概念有所疑惑 , 比如说 map 算子后面接入一个 filter 算子, 而且是同等数量的, 这样我就可以把 map 和 filter 抽象成一个计算进行自动优化, 要达到 chain 的条件比较苛刻, 具体可以查看代码 在 JobGraph 里主要结构就是 JobVertex 和 JobEdge, 在前面所说的 chain 方法后, 可以合并 两个或多个 StreamNode 为一个 JobVertex, 如下图所示: 好了这里基本就聊完了 Client 端的工作 2.2 JobManager 端JobManager 端接收到 client 提交的 JobGraph, 根据 JobgRaph 来生成 ExcutionGraph, 这个 ExcutionGraph 简单来说就是 JobGraph 的并行版本, 定义具体执行的细节: 这里省略了一部分(其他部分一样), 主要来看看几个结构, ExecutionJobVertex 主要类似于 JobGraph 的 Node, 管理所有下面的并行状态, ExecutionVertex 是最小的执行单位(也是我们所说的 SubTask, 每个 SubTask 都由一个 thread 启动), 同理 IntermediateResult 负责多个 IntermediateResultPartition. 到这里完成了 ExecutionGraph, 而需要部署到 TaskManager 中间还需要为每个 Vertex 生成 TaskDeploymentDescriptor, 来描述在 TaskManager 中的具体任务, 比如 inputGates(输入), producedPartition(输出), 然后提交给 TaskManager 2.3 TaskManager 端上面提到 JobManager 生成 TaskDeploymentDescriptor 提交给 TaskManager, TaskManager 就比较好办了, 只需要设定这个 Task 的输入和输出还有 run 这个 Task 即可, 这一层就是所谓的物理执行层. 而对于分布在各个 TaskManager 上的 SubTask 是如何通信的呢, 可以看下图: 对于在同一个 TaskManager 内的 subTask, 通过 InputGate 和 ResultPartition 直接进行通信, 而对于不在同一个 TaskManager 里需要借助 Netty 层进行网络通信: 还有一点值得注意的是, 当有消息来到时 ResultPartition 会给 InputGate 发送 notifyDataAvallable, 告诉下游该来取数了, 如果下游比较忙没空来取的话就会阻塞, 进而逐级向上传导产生被压, 这种缓冲 buffer 的方式是 flink 天然处理被压的方法. 至此整个 Flink Job 的流程已经结束, 但毕竟 Flink 是一个庞大的开源项目, 很多细节比如 Checkpoint 机制, 状态存储这些重要的概念还未涉及, 有兴趣的读者可以参考优秀的 Blog 进一步研究 参考资料: Flink 官网 FLIP Jark’s Blog 玉兆的博客 Flink 官方博客","categories":[{"name":"BigData","slug":"BigData","permalink":"http://yoursite.com/categories/BigData/"}],"tags":[]},{"title":"黑苹果原理","slug":"Hackintosh/principel","date":"2019-12-08T12:19:05.000Z","updated":"2020-01-15T12:06:59.170Z","comments":true,"path":"wiki/Hackintosh/principel/","link":"","permalink":"http://yoursite.com/wiki/Hackintosh/principel/","excerpt":"","text":"操作系统正常启动方式为 UEFI 或者 BIOS, 苹果因为需要各种验证所以中间需要进行一层 mock, 就是常见的 Clover UEFI -&gt; Clover -&gt; Mac OS 所以说如果弄黑苹果最主要的是调整好苹果的 EFI 即可, 理论上可以无痛更新 https://github.com/daliansky/Hackintosh 收集各种型号主机的 EFI 参考资料 关于黑苹果你必须要知道的事儿 tonymacx86","categories":[{"name":"Hackintosh","slug":"Hackintosh","permalink":"http://yoursite.com/categories/Hackintosh/"}],"tags":[]},{"title":"UEFI 与 BIOS","slug":"Hackintosh/uefi_bios","date":"2019-12-08T12:19:05.000Z","updated":"2020-01-15T12:06:59.170Z","comments":true,"path":"wiki/Hackintosh/uefi_bios/","link":"","permalink":"http://yoursite.com/wiki/Hackintosh/uefi_bios/","excerpt":"","text":"1980s 开始 BIOS 系统 应对 BIOS 限制, 2006 年 Intel 开发 EFI, 苹果采用 2007 年 UEFI 问世, 统一标准","categories":[{"name":"Hackintosh","slug":"Hackintosh","permalink":"http://yoursite.com/categories/Hackintosh/"}],"tags":[]},{"title":"环境变量","slug":"Linux/env","date":"2019-11-12T08:14:06.000Z","updated":"2020-01-15T12:06:59.171Z","comments":true,"path":"wiki/Linux/env/","link":"","permalink":"http://yoursite.com/wiki/Linux/env/","excerpt":"","text":"","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[],"author":"Limbo"},{"title":"shell","slug":"Linux/shell","date":"2019-11-12T08:14:06.000Z","updated":"2020-01-21T08:39:05.718Z","comments":true,"path":"wiki/Linux/shell/","link":"","permalink":"http://yoursite.com/wiki/Linux/shell/","excerpt":"","text":"Shell 原理系统提供 shell 给用户调用内核 执行过程: 读取用户键盘指令 分析命令，以命令名作为文件名，并将其它参数改造为系统调用 execve() 内部处理所要求的形式 终端进程调用 fork() 建立一个子进程 终端进程本身用系统调用 wait4() 来等待子进程完成(如果是后台命令，则不等待). 当子进程运行时调用 execve()，子进程根据文件名(即命令名)到目录中查找有关文件(这是命令解释程序构成的文件), 将它调入内存, 执行这个程序(解释这条命令) 如果命令末尾有&amp;号(后台命令符号), 则终端进程不用系统调用 wait4() 等待, 立即发提示符, 让用户输入下一个命令, 转 1 如果命令末尾没有 &amp; 号, 则终端进程要一直等待, 当子进程(即运行命令的进程)完成处理后终止, 向父进程(终端进程)报告, 此时终端进程醒来, 在做必要的判别等工作后, 终端进程发提示符, 让用户输入新的命令, 重复上述处理过程. 内置 Shell 命令 Shell navigation","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[],"author":"Limbo"},{"title":"unix 哲学","slug":"Linux/unix","date":"2019-11-12T08:14:06.000Z","updated":"2020-01-15T12:06:59.172Z","comments":true,"path":"wiki/Linux/unix/","link":"","permalink":"http://yoursite.com/wiki/Linux/unix/","excerpt":"","text":"https://zh.wikipedia.org/wiki/Unix%E5%93%B2%E5%AD%A6","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[],"author":"Limbo"},{"title":"shell navigation","slug":"Linux/shell_navigation","date":"2019-11-12T08:14:06.000Z","updated":"2020-01-21T08:36:22.633Z","comments":true,"path":"wiki/Linux/shell_navigation/","link":"","permalink":"http://yoursite.com/wiki/Linux/shell_navigation/","excerpt":"","text":"","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[],"author":"Limbo"},{"title":"Ssh","slug":"Tools/ssh","date":"2019-11-05T09:00:36.000Z","updated":"2020-01-15T12:06:59.163Z","comments":true,"path":"wiki/Tools/ssh/","link":"","permalink":"http://yoursite.com/wiki/Tools/ssh/","excerpt":"","text":"","categories":[{"name":"Tools","slug":"Tools","permalink":"http://yoursite.com/categories/Tools/"}],"tags":[],"author":"Limbo"},{"title":"Git 原理","slug":"Tools/git","date":"2019-11-05T08:58:19.000Z","updated":"2020-01-15T12:06:59.164Z","comments":true,"path":"wiki/Tools/git/","link":"","permalink":"http://yoursite.com/wiki/Tools/git/","excerpt":"","text":"","categories":[{"name":"Tools","slug":"Tools","permalink":"http://yoursite.com/categories/Tools/"}],"tags":[],"author":"Limbo"},{"title":"使用 maven shade plugin 解决重复类问题","slug":"Language/Java/shaded","date":"2019-11-03T02:36:03.000Z","updated":"2020-01-15T12:06:59.169Z","comments":true,"path":"wiki/Language/Java/shaded/","link":"","permalink":"http://yoursite.com/wiki/Language/Java/shaded/","excerpt":"","text":"使用 Maven 大概都遇到过重复类的问题, 轻则程序异常, 重则无法运行, 一般有一下几个方法来处理: maven &lt;exclusions&gt; 用来排除重复类, 只对兼容性好的依赖有效, 如果两个版本依赖的接口有变动就 GG 了 可以祭出大招 classloader 来加载不同的类, 这个方法可以 cover 所有重复类, 但是有个缺点就是代码侵入性比较强, 我就是想引两个版本还要写一堆代码, 岂不是蛋疼 使用框架, 比如说阿里的 sofa-jarslink, 其本质也是基于 classloader 在底层进行封装 使用 Maven Shade Plugin 进行类名转换, 然后引入依赖, 对于用 1 方法不见效, 又不想使用 2 方法来说, 这个是很好的折衷, 不用对代码进行更改, 只需要修改 pom 文件 去 官网 看看 Maven Shade Plugin 可以干什么? 可以生成 Uber JAR, 而且可以决定 include 和 exclude 重命名 class 防止打成的 Uber Jar 类冲突 设置 mainClass Resource 转换 今天重点来说一下如何使用 Maven Shade Plugin 来实现多版本加载 Maven 依赖原则 优先按照依赖管理中 &lt;dependencyManagement&gt; 指定版本进行仲裁 若无版本声明, 则按照最短路径优先 若路径一致, 则选择最先声明的版本 问题工作中我们搭建的 Flink SQL 平台需要进行 Kafka 的连接, 蛋疼的是生产上 Kafka 版本有几种, 短时间内不能统一, 需要兼容各个版本, 如下图所示: 根据 Maven 依赖的原则, 在 pom 里优先加载了 Kafka-client-0.8, 轮到加载 Kafka-client-0.11 认为该依赖是重复的, 并不在 classloader 里进行加载, 解决方法 为了便于维护管理可以将原来的单模块换为多模块, 分别新建 shaded-Kafka-connector-0.8 和 shaded-Kafka-connector-0.11 模块, 注意里面不用写代码, 仅仅写一个 pom 文件即可 shaded 模块中引入各自的 Kafka-connector 依赖, 将 Kafka-client 模块用 Maven shade plugin relocation 到 shaded-Kafka-client 我们的原工程不再引用 Kafka-connector 模块, 而是分别引用 shade-Kafka-connector, 这样就将不通的 Kafka-client 进行了隔离 这个方法有一点坏处就是, 你只能使用生成出来的 Uber JAR 来运行才不会冲突, 像 Idea 里面不会识别这种 shaded 的包, 在 Idea 里运行还是会报错的, 相关 issue 开源软件用法许多开源软件也面临着这个问题, 比如说臭名昭著的 guava 在升级的道路上绝不妥协, 导致兼容性极差, Flink 单独用一个 flink-shade 来单独 shade 一份进行引用 资料 To shade or not to shade","categories":[{"name":"Language","slug":"Language","permalink":"http://yoursite.com/categories/Language/"},{"name":"Java","slug":"Language/Java","permalink":"http://yoursite.com/categories/Language/Java/"}],"tags":[],"author":"Limbo"}]}